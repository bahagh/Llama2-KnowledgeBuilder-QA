{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import xml.etree.ElementTree as ET\n",
        "import re\n",
        "import openai\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SuhEZ2AQ4lab"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yn9aYUQH4Uib"
      },
      "outputs": [],
      "source": [
        "\n",
        "def fetch_papers():\n",
        "    \"\"\"Fetches papers from the arXiv API and returns them as a list of strings.\"\"\"\n",
        "    url = 'http://export.arxiv.org/api/query?search_query=ti:llama&start=0&max_results=70'\n",
        "    response = urllib.request.urlopen(url)\n",
        "    data = response.read().decode('utf-8')\n",
        "    root = ET.fromstring(data)\n",
        "\n",
        "    papers_list = []\n",
        "\n",
        "    for entry in root.findall('{http://www.w3.org/2005/Atom}entry'):\n",
        "        title = entry.find('{http://www.w3.org/2005/Atom}title').text\n",
        "        summary = entry.find('{http://www.w3.org/2005/Atom}summary').text\n",
        "        paper_info = f\"Title: {title}\\nSummary: {summary}\\n\"\n",
        "        papers_list.append(paper_info)\n",
        "\n",
        "    return papers_list\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Remove unwanted characters and symbols from the text.\"\"\"\n",
        "    cleaned_text = re.sub(r\"[^a-zA-Z0-9.,!?]\", \" \", text)\n",
        "    cleaned_text2 = re.sub(\"\\n\", \" \", cleaned_text)\n",
        "    return cleaned_text2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def generate_embeddings(papers_list):\n",
        "    \"\"\"Generate embeddings from the cleaned data based on OpenAI embedding algorithms.\"\"\"\n",
        "    embeddings = []\n",
        "\n",
        "    for paper_info in papers_list:\n",
        "        cleaned_paper_info = clean_text(paper_info)\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": f\"{cleaned_paper_info}\"}\n",
        "            ],\n",
        "            max_tokens=1000\n",
        "        )\n",
        "        embedding = response['choices'][0]['message']['content']\n",
        "        embeddings.append(embedding)\n",
        "\n",
        "    return embeddings\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "papers_list = fetch_papers()\n",
        "embeddings = generate_embeddings(papers_list)"
      ],
      "metadata": {
        "id": "whlgTldfEn_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def answer_question(question, papers_list, embeddings):\n",
        "    \"\"\"Answer a question based on the provided papers_list and embeddings.\"\"\"\n",
        "    cleaned_question = clean_text(question)\n",
        "    messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": f\"{cleaned_question}\"}]\n",
        "\n",
        "\n",
        "    total_tokens = 0\n",
        "    for paper_info, embedding in zip(papers_list, embeddings):\n",
        "\n",
        "        message_length = len(f\"Paper Info: {clean_text(paper_info)}\\nEmbedding: {embedding}\")\n",
        "\n",
        "\n",
        "        if total_tokens + message_length <= 4097:\n",
        "            messages.append({\"role\": \"assistant\", \"content\": f\"Paper Info: {clean_text(paper_info)}\\nEmbedding: {embedding}\"})\n",
        "            total_tokens += message_length\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    # Generate the answer using OpenAI's GPT-3.5 Turbo\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=messages,\n",
        "        max_tokens=1500\n",
        "    )\n",
        "\n",
        "    answer = response['choices'][0]['message']['content']\n",
        "    return answer\n"
      ],
      "metadata": {
        "id": "kHr2ARaL4ix_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_question(\"here should be the input of the user\", papers_list, embeddings)"
      ],
      "metadata": {
        "id": "YDBk2j8E4VhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CMf2Z2bC4VkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IWtw87Gs8zun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "atfyONzV4wus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-1UcAVtW4wxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rrkTs0254w2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_-A3DQw64w5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6xfkJ6Yw4w8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5VLyqMlH4w-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dRfPP--f8zyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukEwKCaX6WCy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vdiFQpF08z17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_question(\"what is Llama-2\", papers_list, embeddings)"
      ],
      "metadata": {
        "id": "OF4Qkvi08z5F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "c60ba7fc-5f0f-4edc-e3d7-6f9720f78fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'LLama 2 refers to Lawyer LLaMA, which is a legal domain large language model (LLM). It is specifically designed to overcome the challenges faced by LLMs in applying their capabilities to specific domains like law. The Lawyer LLaMA model addresses the deficiency in domain-specific knowledge by injecting this knowledge during training and teaching the model professional skills through supervised fine-tuning tasks. It also includes a retrieval module that retrieves relevant legal articles to ensure accurate responses to queries. The study found that incorporating expert knowledge during training is more effective than relying solely on data generated by ChatGPT. The researchers plan to make the Lawyer LLaMA model and its accompanying data available to the public.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rya-e7US8z75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "URnyFvMZ4VmQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PDv1iX8q7Wrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bC2dHIF97Wul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "e8Ws07-J7Wxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NIcJxAYt-iDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_EdSPVM3-iHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZXWc-_dh_K0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xZ1uw1Rh_K3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "7QBj0fOF_K5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "HKPJD5vS_K7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Zp-1AkA_LA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_r8f_p_k_LE6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}